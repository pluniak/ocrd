{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\phili\\anaconda3\\envs\\ocrd\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers.utils import logging\n",
    "logging.set_verbosity_error()\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\phili\\anaconda3\\envs\\ocrd\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "import sys\n",
    "sys.path.append('../src/')\n",
    "from utils.helpers import OCRD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_ocrd_pipeline(img_path, status=gr.Progress(), binarize_mode='detailed', min_pixel_sum=30, median_bounds=(None, None), font_size=30):\n",
    "    \"\"\"\n",
    "    Executes the OCRD pipeline on an image from file loading to text overlay creation. This function orchestrates\n",
    "    the calling of various OCRD class methods to process the image, extract and recognize text, and then overlay\n",
    "    this text on the original image.\n",
    "\n",
    "    Parameters:\n",
    "        img_path (str): Path to the image file.\n",
    "        binarize_mode (str): Mode to be used for image binarization. Can be 'detailed', 'fast', or 'no'.\n",
    "        min_pixel_sum (int, optional): Minimum sum of pixels to consider a text line segmentation for extraction. \n",
    "            If 'default', default values are applied.\n",
    "        median_bounds (tuple, optional): Bounds to filter text line segmentations based on size relative to the median. \n",
    "            If 'default', default values are applied.\n",
    "        font_size (int, optional): Font size to be used in text overlay. If 'default', a default size or scaling logic is applied.\n",
    "\n",
    "    Returns:\n",
    "        Image: An image with overlay text, where text is extracted and recognized from the original image.\n",
    "\n",
    "    This function handles:\n",
    "    - Image binarization.\n",
    "    - Text line segmentation.\n",
    "    - Text line extraction and deskewing.\n",
    "    - Optical character recognition on text lines.\n",
    "    - Creating an image overlay with recognized text.\n",
    "    \"\"\"\n",
    "    \n",
    "    # prepare kwargs\n",
    "    efadt_kwargs = {}\n",
    "    if min_pixel_sum != 'default':\n",
    "        efadt_kwargs['min_pixel_sum'] = min_pixel_sum\n",
    "    if median_bounds != 'default':\n",
    "        efadt_kwargs['median_bounds'] = median_bounds\n",
    "\n",
    "    ctoi_kwargs = {}\n",
    "    if font_size != 'default':\n",
    "        ctoi_kwargs['font_size'] = font_size\n",
    "\n",
    "    # run pipeline\n",
    "    #status(0, desc=\"\\nReading image...\\n\")\n",
    "    ocrd = OCRD(img_path)\n",
    "    status(0, desc='\\nStep 1/5: Binarizing image...\\n')\n",
    "    binarized = ocrd.binarize_image(ocrd.image, binarize_mode)\n",
    "    status(0, desc='\\nStep 2/5: Segmenting textlines...\\n')\n",
    "    textline_segments = ocrd.segment_textlines(binarized)\n",
    "    status(0, desc='\\nStep 3/5: Extracting, filtering and de-skewing textlines...\\n')\n",
    "    image_scaled = ocrd.scale_image(ocrd.image)  # textline_segments were predicted on rescaled image\n",
    "    textline_images, _ = ocrd.extract_filter_and_deskew_textlines(image_scaled, textline_segments[...,0], **efadt_kwargs)\n",
    "    status(0, desc='\\nStep 4/5: OCR on textlines...\\n')\n",
    "    textline_preds = ocrd.ocr_on_textlines(textline_images)\n",
    "    status(0, desc='\\nStep 5/5: Creating output overlay image...')\n",
    "    img_gen = ocrd.create_text_overlay_image(textline_images, textline_preds, (image_scaled.shape[0], image_scaled.shape[1]), **ctoi_kwargs)\n",
    "    status(1, desc='\\nJOB COMPLETED\\n')\n",
    "\n",
    "    return img_gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "demo_data = [\n",
    "    'https://github.com/pluniak/ocrd/blob/main/src/demo_data/act_image.jpg',\n",
    "    'https://github.com/pluniak/ocrd/blob/main/src/demo_data/newjersey1_image.jpg',\n",
    "    'https://github.com/pluniak/ocrd/blob/main/src/demo_data/newjersey2_image.jpg',\n",
    "    'https://github.com/pluniak/ocrd/blob/main/src/demo_data/notes_image.jpg',\n",
    "    'https://github.com/pluniak/ocrd/blob/main/src/demo_data/washington_image.jpg'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "demo_data = [\n",
    "    '../src/demo_data/act_image.jpg',\n",
    "    '../src/demo_data/newjersey1_image.jpg',\n",
    "    '../src/demo_data/newjersey2_image.jpg',\n",
    "    '../src/demo_data/notes_image.jpg',\n",
    "    '../src/demo_data/washington_image.jpg'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "iface = gr.Interface(run_ocrd_pipeline,\n",
    "                     title=\"OCRD Pipeline\",\n",
    "                     description=\"<ul><li>This interactive demo showcases an 'Optical Character Recognition Digitization' pipeline that processes \\\n",
    "                                  images to recognize text.</li> \\\n",
    "                                  <li>Steps include binarization, text line segmentation, extraction, filtering and deskewing as well as OCR. \\\n",
    "                                  Results are displayed as a generated overlay image.</li> \\\n",
    "                                  <li>Optimized for English; other languages (e.g. German) may require OCR model fine-tuning.</li> \\\n",
    "                                  <li>Uses free CPU-based compute, which is rather slow. A pipeline run will take up to 10 minutes. \\\n",
    "                                  For lengthy waits, example results are available for download: .</li> \\\n",
    "                                  <li>Note: The demo is just a first version! OCR performance and computation speed can be optimized.</li> \\\n",
    "                                  <li>The demo is based on code from my GitHub repository: https://github.com/pluniak/ocrd/tree/main</li></ul>\",\n",
    "                     inputs=[gr.Image(type='filepath', label='Input image')],\n",
    "                     outputs=gr.Image(label='Output image: overlay with recognized text', type='pil', format='jpeg'),\n",
    "                     examples=demo_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:8901\n",
      "Running on public URL: https://68fad7d110a20e4ae7.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://68fad7d110a20e4ae7.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching 6 files: 100%|██████████| 6/6 [00:00<00:00, 6068.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\phili\\anaconda3\\envs\\ocrd\\lib\\site-packages\\keras\\src\\saving\\legacy\\saved_model\\load.py:107: The name tf.gfile.Exists is deprecated. Please use tf.io.gfile.exists instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\phili\\anaconda3\\envs\\ocrd\\lib\\site-packages\\keras\\src\\engine\\functional.py:156: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\phili\\anaconda3\\envs\\ocrd\\lib\\site-packages\\keras\\src\\layers\\pooling\\max_pooling2d.py:161: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\phili\\anaconda3\\envs\\ocrd\\lib\\site-packages\\keras\\src\\saving\\legacy\\saved_model\\load.py:178: The name tf.logging.warning is deprecated. Please use tf.compat.v1.logging.warning instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\phili\\anaconda3\\envs\\ocrd\\lib\\site-packages\\keras\\src\\saving\\legacy\\saved_model\\load.py:178: The name tf.logging.warning is deprecated. Please use tf.compat.v1.logging.warning instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "Fetching 6 files: 100%|██████████| 6/6 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kept 78 of 143 text segments after filtering.\n",
      "All segments deleted smaller than 30 pixels (absolute min size).\n",
      "Processing textline no. 1 of 78\n",
      "Processing textline no. 11 of 78\n"
     ]
    }
   ],
   "source": [
    "iface.launch(share=True, \n",
    "             server_port=8901)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "iface.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ocrd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
