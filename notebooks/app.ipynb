{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\phili\\anaconda3\\envs\\ocrd\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from transformers.utils import logging\n",
    "logging.set_verbosity_error()\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\phili\\anaconda3\\envs\\ocrd\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "import sys\n",
    "sys.path.append('../src/')\n",
    "from utils.helpers import OCRD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_ocrd_pipeline(img_path, font_size='small', binarize_mode='detailed', min_pixel_sum=30, median_bounds=(None, None), status=gr.Progress()):\n",
    "    \"\"\"\n",
    "    Executes the OCRD pipeline on an image from file loading to text overlay creation. This function orchestrates\n",
    "    the calling of various OCRD class methods to process the image, extract and recognize text, and then overlay\n",
    "    this text on the original image.\n",
    "    Parameters:\n",
    "        img_path (str): Path to the image file.\n",
    "        font_size (int, optional): Font size to be used in text overlay. Can be 'small', 'medium', 'large' or 'adjusted'.\n",
    "            If set to 'adjusted', the font size is dynamically adjusted to fit the text within its bounding box width.\n",
    "        binarize_mode (str): Mode to be used for image binarization. Can be 'detailed', 'fast', or 'no'.\n",
    "        min_pixel_sum (int, optional): Minimum sum of pixels to consider a text line segmentation for extraction. \n",
    "            If 'default', the default value (see function definition) is applied. Set to None for no filtering.\n",
    "        median_bounds (tuple, optional): Bounds to filter text line segmentations based on size relative to the median. \n",
    "            If 'default', default values (see function definition) are applied. Set to None for no filtering.\n",
    "    Returns:\n",
    "        Image: An image with overlay text, where text is extracted and recognized from the original image.\n",
    "    This function handles:\n",
    "    - Image binarization.\n",
    "    - Text line segmentation.\n",
    "    - Text line extraction and deskewing.\n",
    "    - Optical character recognition on text lines.\n",
    "    - Creating an image overlay with recognized text.\n",
    "    \"\"\"\n",
    "    \n",
    "    # convert gradio app dropdown options\n",
    "    if font_size == 'small':\n",
    "        font_size = 30\n",
    "    if font_size == 'medium':\n",
    "        font_size = 50\n",
    "    if font_size == 'large':\n",
    "        font_size = 70\n",
    "    elif font_size == 'adjusted':\n",
    "        font_size = -1\n",
    "\n",
    "    # prepare kwargs\n",
    "    efadt_kwargs = {}\n",
    "    if min_pixel_sum != 'default':\n",
    "        efadt_kwargs['min_pixel_sum'] = min_pixel_sum\n",
    "    if median_bounds != 'default':\n",
    "        efadt_kwargs['median_bounds'] = median_bounds\n",
    "\n",
    "    ctoi_kwargs = {}\n",
    "    if font_size != 'default':\n",
    "        ctoi_kwargs['font_size'] = font_size\n",
    "\n",
    "    # run pipeline\n",
    "    ocrd = OCRD(img_path)\n",
    "    status(0, desc='\\nStep 1/5: Binarizing image...\\n')\n",
    "    binarized = ocrd.binarize_image(ocrd.image, binarize_mode)\n",
    "    status(0, desc='\\nStep 2/5: Segmenting textlines...\\n')\n",
    "    textline_segments = ocrd.segment_textlines(binarized)\n",
    "    status(0, desc='\\nStep 3/5: Extracting, filtering and de-skewing textlines...\\n')\n",
    "    image_scaled = ocrd.scale_image(ocrd.image)  # textline_segments were predicted on rescaled image\n",
    "    textline_images, _ = ocrd.extract_filter_and_deskew_textlines(image_scaled, textline_segments[...,0], **efadt_kwargs)\n",
    "    status(0, desc='\\nStep 4/5: OCR on textlines...\\n')\n",
    "    textline_preds = ocrd.ocr_on_textlines(textline_images)\n",
    "    status(0, desc='\\nStep 5/5: Creating output overlay image...')\n",
    "    img_gen = ocrd.create_text_overlay_image(textline_images, textline_preds, (image_scaled.shape[0], image_scaled.shape[1]), **ctoi_kwargs)\n",
    "    status(1, desc='\\nJOB COMPLETED\\n')\n",
    "\n",
    "    return img_gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "demo_data = [\n",
    "    ['../data/demo_data/act_image.jpg', None],\n",
    "    ['../data/demo_data/newjersey2_image.jpg', None],\n",
    "    ['../data/demo_data/washington_image.jpg', None]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "description = \"\"\"<ul>\n",
    "                    <li>This interactive demo showcases an 'Optical Character Recognition Digitization' pipeline that processes images to recognize text.</li>\n",
    "                    <li>Steps include:\n",
    "                        <ol>\n",
    "                            <li>Image binarization</li>\n",
    "                            <li>Text line segmentation</li>\n",
    "                            <li>Text line extraction, filtering and deskewing</li>\n",
    "                            <li>OCR on textlines</li>\n",
    "                            <li>Printing recognized text on generated image for visualization</li>\n",
    "                        </ol>\n",
    "                    </li>\n",
    "                    <li>Optimized for <b>English</b>; other languages (e.g., German) may require OCR model fine-tuning.</li>\n",
    "                    <li>Uses free CPU-based compute, which is rather slow. Depending on the input image, a pipeline run can take over 10 minutes.</li> \n",
    "                    <li>For lengthy waits, look at these <b>pre-computed examples</b>: <a href='https://github.com/pluniak/ocrd/tree/main/data/demo_data'>https://github.com/pluniak/ocrd/tree/main/data/demo_data</a></li>\n",
    "                    <li>The demo is based on code from my GitHub repository: <a href='https://github.com/pluniak/ocrd'>https://github.com/pluniak/ocrd</a></li>\n",
    "                    <li>Note: The demo is just a <b>first prototype</b>! OCR performance and computation speed should be optimized.</li>\n",
    "                    <li>Please <b>keep this page untouched</b> during the pipeline run to prevent errors.</li>\n",
    "                </ul>\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "iface = gr.Interface(fn = run_ocrd_pipeline,\n",
    "                     title=\"OCRD Pipeline\",\n",
    "                     description=description,\n",
    "                     inputs=[\n",
    "                         gr.Image(type='filepath', label='Input image'), \n",
    "                         gr.Dropdown(choices=['small', 'medium', 'large', 'adjusted'], label='Output image font size', value='small', \n",
    "                                     info='\"adjusted\" will try to mimic font sizes from the input image')\n",
    "                     ],\n",
    "                     outputs=gr.Image(label='Output image: overlay with recognized text', type='pil', format='jpeg'),\n",
    "                     examples=demo_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:8900\n",
      "Running on public URL: https://8751142c3235aa3547.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://8751142c3235aa3547.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iface.launch(share=True, \n",
    "             server_port=8900)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "iface.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ocrd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
